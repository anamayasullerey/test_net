{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two stage neural network implementation for MNIST digits classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This is a step by step implementation of a multilayer neural network for [MNIST](https://en.wikipedia.org/wiki/MNIST_database) digit classification using nn_framework. Input images in MNIST database are 28x28 pixels. Images are black and white so one bit is required to represents each pixel. This neural network classifies input image to one of the possible digits (0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages\n",
    "nn_framework and mnist packages are in the src directory. **\"nnf install path\"/nnf/src** directory needs to be in $PYTHONPATH for these packages to load.\n",
    "* mnist package is used for loading mnist data and other related functions.\n",
    "* nn_framework package that has the components to build a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist.utils.load_mnist as load_mnist\n",
    "import nn_framework.neural_network as nn\n",
    "import nn_framework.layer_dict as ld\n",
    "import nn_framework.weight_update_params as wup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST data\n",
    "load_mnist function returns training data, validation data and test data as three numpy arrays.\n",
    "Shape of these arrays is Number of samples * 795.\n",
    "\n",
    "![title](data_matrix_shape.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the training, validation and test data\n",
    "# Each data is a numpy array of shape Number of Samples * 795\n",
    "# 0:783 are inputs, 784:793 are outputs, 794 is classified output\n",
    "# N is chose as first dimention as it is easy to shuffle training data\n",
    "# during training\n",
    "training_data, validation_data, test_data = load_mnist.load_mnist()\n",
    "\n",
    "validation_x = np.transpose(validation_data[:, 0:784]) \n",
    "validation_y_class = np.transpose(validation_data[:, 794])\n",
    "val_acc = lambda: net.classification_accuracy(validation_x, validation_y_class)\n",
    "\n",
    "test_x = np.transpose(test_data[:, 0:784]) \n",
    "test_y_class = np.transpose(test_data[:, 794])\n",
    "test_acc = lambda: net.classification_accuracy(test_x, test_y_class)\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network architecture\n",
    "The MNIST digit classifier net in this eaxmaple has the following architecture.\n",
    "![title](mnist_net_arch.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the net object\n",
    "In nn_framework a net object is created layer by layer. The first step is to create a net object. Input layer is created automatically when a net is created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Network - specify input layer neurons (28x28=784)\n",
    "net = nn.NeuralNetwork(\"test_net\", 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding layers\n",
    "Layers are added sequentially to the net. Last layer added has to be an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3081433aeaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creating Neural Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Step 1: Create Network - specify input layer neurons (28x28=784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_net\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 2: Add hidden layers in sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Fully connected layer of 800 neurons\n",
    "layer = ld.hdict[\"fc\"](800)\n",
    "net.add_layer(layer)\n",
    "\n",
    "# Relu activation layer of 800 neurons\n",
    "layer = ld.hdict[\"relu\"](800)\n",
    "net.add_layer(layer)\n",
    "\n",
    "# Fully connected layer of 80 neurons\n",
    "layer = ld.hdict[\"fc\"](80)\n",
    "net.add_layer(layer)\n",
    "\n",
    "# Fully connected layer of 80 neurons\n",
    "layer = ld.hdict[\"relu\"](80)\n",
    "net.add_layer(layer)\n",
    "\n",
    "# Fully connected layer of 10 neurons\n",
    "layer = ld.hdict[\"fc\"](10)\n",
    "net.add_layer(layer)\n",
    "\n",
    "# Add softmax output layer\n",
    "layer = ld.odict[\"softmax\"](10)\n",
    "net.add_layer(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.check_arch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Specify L2 loss coeffcient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify l2 loss\n",
    "net.set_l2_loss_coeff(.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set weight update method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weight update method\n",
    "params = wup.GradientDescentParams(.3)\n",
    "# params = wup.MomentumParams(.3)\n",
    "# params = wup.AdamParams()\n",
    "net.set_weight_update_function(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For repeatability during testing\n",
    "np.random.seed(1)\n",
    "# Initialize the network\n",
    "net.initialize_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set training related parameters\n",
    "mini_batch_size = 32\n",
    "epochs = 20\n",
    "verbose = 0\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(\"Epoch \" + str(epoch))\n",
    "    np.random.shuffle(training_data)\n",
    "    mini_batches = [training_data[k:k + mini_batch_size, :] for k in\n",
    "                   range(0, len(training_data), mini_batch_size)]\n",
    "    for count, mini_batch in enumerate(mini_batches, start=1):\n",
    "        x = np.transpose(mini_batch[:, 0:784])\n",
    "        y = np.transpose(mini_batch[:, 784:794])\n",
    "        net.train(x, y)\n",
    "        if ((count%100 == 0) and verbose):\n",
    "            print(\"Count {0} validation data accuracy = {1} %.\".format(count, val_acc()))\n",
    "            print()\n",
    "            \n",
    "        \n",
    "    print(\"Epoch {0} validation data accuracy = {1} %.\".format(epoch, val_acc()))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Test data accuracy = {0} %.\".format(test_acc()))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
